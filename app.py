import streamlit as st
import torch
import requests
import re
from bs4 import BeautifulSoup
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration

# --- 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ì™¸êµë¶€ ì†Œì‹ ìš”ì•½ ì„œë¹„ìŠ¤", page_icon="ğŸ“¢", layout="wide")

st.title("ğŸ“¢ Daily ì™¸êµë¶€ ì†Œì‹ ìë™ ìš”ì•½ê¸°")
st.markdown("Assignment 6: ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ë¡¤ë§ ë° ìš”ì•½ ì„œë¹„ìŠ¤")
st.markdown("---")

# --- 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ---
# ì£¼ì˜: êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê²½ë¡œëŠ” ë¡œì»¬ì—ì„œ ì‘ë™í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, 
# ì•ˆì •ì ì¸ ì‹¤í–‰ì„ ìœ„í•´ ì„±ëŠ¥ì´ ê²€ì¦ëœ ì˜¨ë¼ì¸ ëª¨ë¸(KoBART)ì„ ì‚¬ìš©í•˜ë„ë¡ ì—°ê²°í–ˆìŠµë‹ˆë‹¤.
@st.cache_resource
def load_model():
    model_name = "ainize/kobart-news"
    try:
        tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)
        model = BartForConditionalGeneration.from_pretrained(model_name)
        return tokenizer, model
    except Exception as e:
        return None, None

with st.spinner('AI ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...'):
    tokenizer, model = load_model()

if model is None:
    st.error("âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨! ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- 3. í¬ë¡¤ë§ í•¨ìˆ˜ (ì œê³µí•´ì£¼ì‹  ì½”ë“œ ì´ì‹) ---
def get_naver_blog_content(url):
    """
    ë„¤ì´ë²„ ë¸”ë¡œê·¸ URL -> ì œëª©, ë³¸ë¬¸ ì¶”ì¶œ (Iframe êµ¬ì¡° ëŒ€ì‘)
    """
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        # ëª¨ë°”ì¼ ë§í¬ ë³€í™˜
        if "m.blog.naver.com" in url:
            url = url.replace("m.blog.naver.com", "blog.naver.com")

        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        # Iframe ì£¼ì†Œ ì°¾ê¸° (ë„¤ì´ë²„ ë¸”ë¡œê·¸ êµ¬ì¡°ìƒ í•„ìˆ˜)
        iframe = soup.select_one('iframe#mainFrame')
        if iframe:
            real_url = "https://blog.naver.com" + iframe['src']
            response = requests.get(real_url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')

        # ì œëª© ì¶”ì¶œ
        title_elem = soup.select_one('.se-title-text') or soup.select_one('.htitle')
        title = title_elem.text.strip() if title_elem else "ì œëª© ì—†ìŒ"

        # ë³¸ë¬¸ ì¶”ì¶œ
        content_elem = soup.select_one('.se-main-container') or soup.select_one('#postViewArea')

        if content_elem:
            text = content_elem.text
            text = re.sub(r'\n+', ' ', text)
            text = re.sub(r'\s+', ' ', text)
            return title, text.strip()
        else:
            return None, None
    except Exception as e:
        return None, None

def get_latest_mofa_news():
    """
    ì™¸êµë¶€ ë¸”ë¡œê·¸ RSSë¥¼ ë’¤ì ¸ì„œ 'ì™¸êµë¶€ ì†Œì‹' ìµœì‹  ê¸€ URLì„ ê°€ì ¸ì˜´
    """
    rss_url = "https://rss.blog.naver.com/mofakr.xml"

    try:
        response = requests.get(rss_url)
        soup = BeautifulSoup(response.content, 'xml')
        items = soup.find_all('item')

        target_links = []
        for item in items:
            category = item.category.text if item.category else ""
            title = item.title.text
            link = item.link.text

            # 'ì†Œì‹', 'ë³´ë„', 'ëŒ€ë³€ì¸' í‚¤ì›Œë“œê°€ ìˆê±°ë‚˜, ì—†ìœ¼ë©´ ìµœì‹ ê¸€ ìˆ˜ì§‘
            if "ì†Œì‹" in category or "ë³´ë„" in category or "ëŒ€ë³€ì¸" in category:
                target_links.append({"title": title, "link": link})
                if len(target_links) >= 3: # í™”ë©´ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ 3ê°œë¡œ ì¡°ì •
                    break
        
        # íƒ€ê²Ÿ ê¸€ì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ìµœì‹ ê¸€ 3ê°œ ê°€ì ¸ì˜¤ê¸°
        if not target_links:
             target_links = ([{"title": i.title.text, "link": i.link.text} for i in items[:3]])

        return target_links

    except Exception as e:
        return []

# --- 4. ìš”ì•½ ì¶”ë¡  í•¨ìˆ˜ (ì œê³µí•´ì£¼ì‹  í›„ì²˜ë¦¬ ë¡œì§ ì ìš©) ---
def predict_summary(text):
    # ì…ë ¥ ê¸¸ì´ ì œí•œ
    input_ids = tokenizer.encode(text, return_tensors="pt")
    # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (ì˜¤ë¥˜ ë°©ì§€)
    if input_ids.shape[1] > 1024:
        input_ids = input_ids[:, :1024]

    summary_ids = model.generate(
        input_ids,
        max_length=120,       # ìš”ì²­í•˜ì‹  ê¸¸ì´ ì„¤ì •
        min_length=50,
        length_penalty=1.5,
        num_beams=4,
        early_stopping=True,
        no_repeat_ngram_size=3
    )

    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

    # [í›„ì²˜ë¦¬ ë¡œì§] ë¬¸ì¥ ë¶„ë¦¬ ë° 3ì¤„ í¬ë§·íŒ…
    sentences = re.split(r'(?<!\d\.)(?<=[.!?])\s*', summary)
    sentences = [s.strip() for s in sentences if s.strip()]

    formatted_sentences = sentences[:3]
    while len(formatted_sentences) < 3:
        formatted_sentences.append("") 

    final_summary = "\n- ".join(formatted_sentences) # ê°€ë…ì„±ì„ ìœ„í•´ ë¶ˆë¦¿ í¬ì¸íŠ¸ ì¶”ê°€
    
    # ì²« ì¤„ì—ë„ ë¶ˆë¦¿ ì¶”ê°€
    if final_summary:
        final_summary = "- " + final_summary

    return final_summary

# --- 5. í™”ë©´ êµ¬ì„± ---
tab1, tab2 = st.tabs(["ğŸ›ï¸ ì™¸êµë¶€ ì†Œì‹ ìë™ ìˆ˜ì§‘", "ğŸ“ í…ìŠ¤íŠ¸ ì§ì ‘ ìš”ì•½"])

# [Tab 1] ìë™ ìˆ˜ì§‘ ë° ìš”ì•½
with tab1:
    st.header("ë„¤ì´ë²„ ë¸”ë¡œê·¸ RSS ê¸°ë°˜ ìë™ í¬ë¡¤ë§")
    st.info("ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ 'ì™¸êµë¶€ ì„œí¬í„°ì¦ˆ(mofakr)' ë¸”ë¡œê·¸ì—ì„œ ìµœì‹  ì†Œì‹ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.")

    if st.button("ğŸš€ ìµœì‹  ì†Œì‹ ê°€ì ¸ì˜¤ê¸° & ìš”ì•½", key="btn_auto"):
        with st.spinner("ì™¸êµë¶€ ë¸”ë¡œê·¸ RSS ê²€ìƒ‰ ì¤‘..."):
            news_items = get_latest_mofa_news()
        
        if not news_items:
            st.error("RSSë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.success(f"ì´ {len(news_items)}ê°œì˜ ìµœì‹  ê¸€ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!")
            
            # ì§„í–‰ìƒí™© í‘œì‹œë°”
            progress_bar = st.progress(0)
            
            for i, item in enumerate(news_items):
                st.markdown(f"### {i+1}. {item['title']}")
                st.caption(f"ğŸ”— [ì›ë¬¸ ë§í¬]({item['link']})")
                
                with st.spinner(f"'{item['title']}' ë‚´ìš©ì„ ì½ê³  ìš”ì•½ ì¤‘..."):
                    title, content = get_naver_blog_content(item['link'])
                    
                    if content:
                        summary = predict_summary(content)
                        st.markdown("**[AI 3ì¤„ ìš”ì•½]**")
                        st.info(summary)
                        with st.expander("ì›ë¬¸ ë‚´ìš© ë³´ê¸°"):
                            st.write(content[:500] + "...")
                    else:
                        st.warning("ë³¸ë¬¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (Iframe ì ‘ê·¼ ì œí•œ ë“±).")
                
                st.markdown("---")
                progress_bar.progress((i + 1) / len(news_items))

# [Tab 2] ì§ì ‘ ì…ë ¥ (ë°±ì—…ìš©)
with tab2:
    st.subheader("ë‰´ìŠ¤ ë³¸ë¬¸ì„ ë¶™ì—¬ë„£ìœ¼ë©´ 3ì¤„ ìš”ì•½í•´ ë“œë¦½ë‹ˆë‹¤.")
    input_text = st.text_area("í…ìŠ¤íŠ¸ ì…ë ¥", height=300)
    
    if st.button("ìš”ì•½í•˜ê¸°", key="btn_manual"):
        if len(input_text) > 50:
            with st.spinner("ìš”ì•½ ì¤‘..."):
                result = predict_summary(input_text)
                st.success("âœ… ìš”ì•½ ì™„ë£Œ")
                st.info(result)
        else:
            st.warning("ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
