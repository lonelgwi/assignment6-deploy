import streamlit as st
import torch
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration
import requests
from bs4 import BeautifulSoup
import re

# 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ì™¸êµë¶€ ì†Œì‹ ìš”ì•½ ë´‡", page_icon="ğŸ¤–")

# 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (íŒŒì¼ ì—†ì–´ë„ ë¨! ì¸í„°ë„·ì—ì„œ ë°›ì•„ì˜´)
@st.cache_resource
def load_model():
    try:
        # ê¹ƒí—ˆë¸Œ ìš©ëŸ‰ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ê³µê°œëœ 'KoBART ìš”ì•½ ëª¨ë¸'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        model_name = "gogamza/kobart-summarization" 
        tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)
        model = BartForConditionalGeneration.from_pretrained(model_name)
        return tokenizer, model
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None, None

tokenizer, model = load_model()

# 3. í…ìŠ¤íŠ¸ ìš”ì•½ í•¨ìˆ˜
def summarize_text(text):
    if not text or len(text) < 50:
        return "ìš”ì•½í•  ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤."
    
    # ëª¨ë¸ì´ ì½ê¸° ì¢‹ê²Œ ì…ë ¥ ë°ì´í„°ë¡œ ë³€í™˜
    input_ids = tokenizer.encode(text, return_tensors="pt")

    # ëª¨ë¸ì´ ìš”ì•½ë¬¸ ìƒì„± (ì˜µì…˜ ì¡°ì ˆë¡œ í’ˆì§ˆ í–¥ìƒ)
    summary_text_ids = model.generate(
        input_ids=input_ids,
        bos_token_id=model.config.bos_token_id,
        eos_token_id=model.config.eos_token_id,
        length_penalty=2.0,
        max_length=128,
        min_length=32,
        num_beams=4,
    )
    
    return tokenizer.decode(summary_text_ids[0], skip_special_tokens=True)

# 4. ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§ í•¨ìˆ˜ (Iframe í•´ê²°)
def get_naver_blog_content(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        
        # ëª¨ë°”ì¼ ì£¼ì†Œ ëŒ€ì‘
        if "m.blog.naver.com" in url:
            url = url.replace("m.blog.naver.com", "blog.naver.com")

        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ëŠ” iframe ì•ˆì— ì§„ì§œ ë‚´ìš©ì´ ìˆ¨ì–´ìˆìŒ
        iframe = soup.select_one("iframe#mainFrame")
        if iframe:
            real_url = "https://blog.naver.com" + iframe["src"]
            response = requests.get(real_url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')

        # ë³¸ë¬¸ ì¶”ì¶œ (ì œëª©ê³¼ ë³¸ë¬¸)
        title_elem = soup.select_one('.se-title-text') or soup.select_one('.htitle')
        title = title_elem.text.strip() if title_elem else "ì œëª© ì—†ìŒ"

        content_elem = soup.select_one('.se-main-container') or soup.select_one('#postViewArea')
        
        if content_elem:
            text = content_elem.text
            text = re.sub(r'\n+', ' ', text) # ì¤„ë°”ê¿ˆ ì •ë¦¬
            return title, text.strip()[:2000] # ë„ˆë¬´ ê¸¸ë©´ ìë¦„
        else:
            return title, None

    except Exception as e:
        return "ì—ëŸ¬", f"í¬ë¡¤ë§ ì‹¤íŒ¨: {e}"

# 5. [ì—…ê·¸ë ˆì´ë“œ] ì™¸êµë¶€ RSSì—ì„œ ìµœì‹  ê¸€ 5ê°œ ê°€ì ¸ì˜¤ê¸°
def get_latest_mofa_news():
    rss_url = "https://rss.blog.naver.com/mofakr.xml"
    try:
        response = requests.get(rss_url)
        # 'xml' íŒŒì„œ ëŒ€ì‹  'html.parser'ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³„ë„ì˜ lxml ì„¤ì¹˜ ì—†ì´ë„ ë™ì‘í•˜ê²Œ ìˆ˜ì •
        soup = BeautifulSoup(response.content, 'html.parser')
        items = soup.find_all('item')
        
        news_list = []
        count = 0
        
        for item in items:
            # ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
            title = item.title.text
            link = item.link.text
            
            # 5ê°œê¹Œì§€ë§Œ ë‹´ê¸°
            news_list.append({"title": title, "link": link})
            count += 1
            if count >= 5:
                break
                
        return news_list
    except Exception as e:
        return []

# --- ë©”ì¸ í™”ë©´ êµ¬ì„± (UI) ---

st.title("ğŸ“° ì™¸êµë¶€ ì†Œì‹ ìë™ ìš”ì•½ ë´‡")
st.write("ì¸ê³µì§€ëŠ¥ì´ ì™¸êµë¶€ì˜ ê¸´ ì†Œì‹ì„ 3ì¤„ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ ë“œë¦½ë‹ˆë‹¤.")

if model is None:
    st.error("âš ï¸ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
else:
    st.success("AI ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ! (Ready)")

# íƒ­ êµ¬ì„±
tab1, tab2 = st.tabs(["ğŸ”— URL ì§ì ‘ ì…ë ¥", "ğŸ“¢ ì™¸êµë¶€ ìµœì‹  ì†Œì‹ (ìë™)"])

# [Tab 1] URL ìš”ì•½
with tab1:
    st.subheader("ë‰´ìŠ¤/ë¸”ë¡œê·¸ ì£¼ì†Œ ì…ë ¥")
    input_url = st.text_input("ìš”ì•½í•˜ê³  ì‹¶ì€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì„ ì…ë ¥í•˜ì„¸ìš”:")
    
    if st.button("ìš”ì•½ ì‹œì‘", key="btn1"):
        if input_url:
            with st.spinner('ë‚´ìš©ì„ ê°€ì ¸ì™€ì„œ ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤...'):
                title, raw_text = get_naver_blog_content(input_url)
                
                if raw_text:
                    summary = summarize_text(raw_text)
                    st.markdown(f"### ğŸ“„ {title}")
                    st.info(summary) # ìš”ì•½ ê²°ê³¼ ì¶œë ¥
                    with st.expander("ì›ë³¸ ë‚´ìš© ë³´ê¸°"):
                        st.write(raw_text)
                else:
                    st.error("ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ê¶Œí•œì´ ì—†ê±°ë‚˜ ì‚­ì œëœ ê¸€ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# [Tab 2] ì™¸êµë¶€ ìµœì‹  ì†Œì‹ (ìš”ì²­í•˜ì‹  ê¸°ëŠ¥!)
with tab2:
    st.subheader("ì™¸êµë¶€ ìµœì‹  ì†Œì‹ (Top 5)")
    st.write("ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì™¸êµë¶€ ë¸”ë¡œê·¸ì˜ ìµœì‹  ê¸€ 5ê°œë¥¼ ê°€ì ¸ì™€ì„œ ìë™ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.")
    
    if st.button("ìµœì‹  ì†Œì‹ ê°€ì ¸ì˜¤ê¸°", key="btn2"):
        with st.spinner('ì™¸êµë¶€ ë¸”ë¡œê·¸ë¥¼ ë°©ë¬¸í•´ì„œ ìµœì‹  ê¸€ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 10~20ì´ˆ ì†Œìš”)'):
            # 1. RSSì—ì„œ ìµœì‹  ê¸€ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            news_items = get_latest_mofa_news()
            
            if not news_items:
                st.error("ì™¸êµë¶€ ì†Œì‹ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            # 2. ê° ê¸€ë§ˆë‹¤ í¬ë¡¤ë§ + ìš”ì•½ ì‹¤í–‰
            for i, item in enumerate(news_items):
                st.markdown(f"---") # êµ¬ë¶„ì„ 
                st.markdown(f"### {i+1}. {item['title']}") # ì œëª© ì¶œë ¥
                
                # ë³¸ë¬¸ ê¸ì–´ì˜¤ê¸°
                _, content = get_naver_blog_content(item['link'])
                
                if content:
                    # ìš”ì•½í•˜ê¸°
                    summary = summarize_text(content)
                    st.success(summary) # ìš”ì•½ ê²°ê³¼ (ì´ˆë¡ìƒ‰ ë°•ìŠ¤)
                else:
                    st.warning("ë³¸ë¬¸ì„ ì½ì„ ìˆ˜ ì—†ëŠ” ê²Œì‹œê¸€ì…ë‹ˆë‹¤.")
