import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import requests
from bs4 import BeautifulSoup
import re

# --- 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ì™¸êµë¶€ ì†Œì‹ ìš”ì•½ ì„œë¹„ìŠ¤", page_icon="ğŸ¤–")

st.title("ğŸ¤– ì¸ê³µì§€ëŠ¥ ë‰´ìŠ¤ ìš”ì•½ ë´‡")
st.write("Assignment 6: ML ëª¨ë¸ ì„œë¹„ìŠ¤í™” í”„ë¡œì íŠ¸")
st.markdown("---")

# --- 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ìºì‹± ê¸°ëŠ¥ìœ¼ë¡œ ì†ë„ í–¥ìƒ) ---
@st.cache_resource
def load_model():
    # ë¡œì»¬ í´ë” ê²½ë¡œ (í´ë” ì´ë¦„ì´ ì •í™•í•´ì•¼ í•©ë‹ˆë‹¤)
    model_path = "./final_model" 
    
    try:
        # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_path)
        return tokenizer, model
    except Exception as e:
        return None, None

# ëª¨ë¸ ë¡œë”© ìƒíƒœ í‘œì‹œ
with st.spinner('AI ëª¨ë¸ì„ ê¹¨ìš°ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)'):
    tokenizer, model = load_model()

if model is None:
    st.error("âš ï¸ 'final_model' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! í´ë” ìœ„ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()
else:
    st.success("âœ… AI ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")

# --- 3. ìš”ì•½ í•¨ìˆ˜ ì •ì˜ ---
def summarize_text(text):
    inputs = tokenizer(
        text, 
        return_tensors="pt", 
        max_length=1024, 
        truncation=True, 
        padding="max_length"
    )
    
    summary_ids = model.generate(
        inputs["input_ids"], 
        max_length=150, 
        min_length=30, 
        length_penalty=2.0, 
        num_beams=4, 
        early_stopping=True
    )
    
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary

# --- 4. ìŠ¤í¬ë ˆì´í•‘ í•¨ìˆ˜ (ì°¨ë‹¨ ë°©ì§€ ì ìš©) ---
def scrape_website(url):
    try:
        # ë¡œë´‡ì´ ì•„ë‹Œ ì²™ ë¸Œë¼ìš°ì € ì •ë³´(User-Agent) ë³´ë‚´ê¸°
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers)
        response.raise_for_status() # 404 ë“± ì—ëŸ¬ ì²´í¬
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë³¸ë¬¸ ì¶”ì¶œ ì‹œë„ (p íƒœê·¸ ìœ„ì£¼)
        paragraphs = soup.find_all('p')
        content = " ".join([p.get_text() for p in paragraphs])
        
        if len(content) < 50: # ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼
            return "ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë³´ì•ˆì´ ê°•í•œ ì‚¬ì´íŠ¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"
            
        return content
    except Exception as e:
        return f"ì—ëŸ¬ ë°œìƒ: {e}"

# --- 5. í™”ë©´ êµ¬ì„± (íƒ­ ê¸°ëŠ¥) ---
tab1, tab2 = st.tabs(["ğŸŒ URLë¡œ ìš”ì•½í•˜ê¸°", "ğŸ“ ì§ì ‘ ì…ë ¥í•´ì„œ ìš”ì•½í•˜ê¸°"])

# [Tab 1] URL ìŠ¤í¬ë ˆì´í•‘ ë°©ì‹
with tab1:
    st.subheader("ë‰´ìŠ¤ ê¸°ì‚¬ ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    url_input = st.text_input("URL ì…ë ¥", placeholder="https://www.mofa.go.kr/...")
    
    if st.button("URL ìš”ì•½ ì‹œì‘", key='btn_url'):
        if url_input:
            with st.spinner('ì‚¬ì´íŠ¸ì— ì ‘ì†í•´ì„œ ê¸€ì„ ì½ëŠ” ì¤‘...'):
                scraped_text = scrape_website(url_input)
                
            if "ì—ëŸ¬ ë°œìƒ" in scraped_text or len(scraped_text) < 50:
                st.warning("âš ï¸ ì´ ì‚¬ì´íŠ¸ëŠ” ë³´ì•ˆ ë•Œë¬¸ì— ë´‡ ì ‘ê·¼ì„ ë§‰ê³  ìˆìŠµë‹ˆë‹¤. ì˜†ì˜ 'ì§ì ‘ ì…ë ¥' íƒ­ì„ ì´ìš©í•´ì£¼ì„¸ìš”!")
                st.write(f"ìƒì„¸ ë©”ì‹œì§€: {scraped_text}")
            else:
                st.info(f"ìˆ˜ì§‘ëœ ê¸€ì ìˆ˜: {len(scraped_text)}ì")
                with st.expander("ì›ë¬¸ ë³´ê¸° (ì ‘ê¸°/í¼ì¹˜ê¸°)"):
                    st.write(scraped_text[:1000] + "...") # ë„ˆë¬´ ê¸°ë‹ˆê¹Œ ì•ë¶€ë¶„ë§Œ
                
                # ìš”ì•½ ìˆ˜í–‰
                with st.spinner('AIê°€ ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤...'):
                    result = summarize_text(scraped_text)
                    st.markdown("### ğŸ“„ ìš”ì•½ ê²°ê³¼")
                    st.success(result)
        else:
            st.warning("ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# [Tab 2] í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥ ë°©ì‹ (í”Œëœ B)
with tab2:
    st.subheader("ë³¸ë¬¸ ë‚´ìš©ì„ ì§ì ‘ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”")
    st.caption("â€» ìŠ¤í¬ë ˆì´í•‘ì´ ì•ˆ ë˜ëŠ” ì‚¬ì´íŠ¸ëŠ” ì—¬ê¸°ì„œ í•´ê²°í•˜ì„¸ìš”!")
    text_input = st.text_area("ê¸°ì‚¬ ë³¸ë¬¸ ë¶™ì—¬ë„£ê¸°", height=300)
    
    if st.button("í…ìŠ¤íŠ¸ ìš”ì•½ ì‹œì‘", key='btn_text'):
        if len(text_input) > 50:
            with st.spinner('AIê°€ ì—´ì‹¬íˆ ìš”ì•½ ì¤‘...'):
                result = summarize_text(text_input)
                st.markdown("### ğŸ“„ ìš”ì•½ ê²°ê³¼")
                st.success(result)
        else:
            st.warning("ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. 50ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# --- 6. ì‚¬ì´ë“œë°” (ì •ë³´ í‘œì‹œ) ---
with st.sidebar:
    st.header("í”„ë¡œì íŠ¸ ì •ë³´")
    st.write("**ì‘ì„±ì:** í™ê¸¸ë™ (ë³¸ì¸ì´ë¦„)")
    st.write("**ì‚¬ìš© ëª¨ë¸:** T5 / Bart (í•™ìŠµì‹œí‚¨ ëª¨ë¸ëª…)")
    st.write("**ë²„ì „:** 1.0.0")
    st.info("ì´ ì„œë¹„ìŠ¤ëŠ” Assignment 6 ê³¼ì œ ì œì¶œìš©ì…ë‹ˆë‹¤.")
