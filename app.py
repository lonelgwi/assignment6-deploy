import streamlit as st
import torch
import requests
import re
from bs4 import BeautifulSoup
# í˜¸í™˜ì„±ì„ ìœ„í•´ AutoTokenizer ì‚¬ìš©
from transformers import AutoTokenizer, BartForConditionalGeneration

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ì œëª©ê³¼ ì•„ì´ì½˜ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ì™¸êµë¶€ ì†Œì‹ ìš”ì•½ ë´‡", page_icon="ğŸ“¢", layout="wide")

# ==========================================
# [1] ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ (ì¸í„°ë„·ì—ì„œ ë‹¤ìš´ë¡œë“œ)
# ==========================================
@st.cache_resource
def load_model():
    # í•œêµ­ì–´ ë‰´ìŠ¤ ìš”ì•½ì— íŠ¹í™”ëœ ê³µê°œ ëª¨ë¸ ì‚¬ìš©
    model_name = "ainize/kobart-news"
    
    try:
        # [í•µì‹¬ ìˆ˜ì •] use_fast=Falseë¥¼ ê¼­ ë„£ì–´ì•¼ 'add_prefix_space' ì—ëŸ¬ê°€ ì•ˆ ë‚©ë‹ˆë‹¤!
        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
        model = BartForConditionalGeneration.from_pretrained(model_name)
        return tokenizer, model
    except Exception as e:
        # ì—ëŸ¬ê°€ ë‚˜ë©´ í™”ë©´ì— ì´ìœ ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ë°˜í™˜
        return None, str(e)

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ë¡œë”© ì¤‘ í‘œì‹œ)
with st.spinner('ì¸í„°ë„·ì—ì„œ AI ëª¨ë¸(KoBART)ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
    result = load_model()
    
    # ê²°ê³¼ê°€ íŠœí”Œì¸ì§€ í™•ì¸ (ì„±ê³µ ì‹œ tokenizer, model ë°˜í™˜)
    if isinstance(result, tuple) and len(result) == 2:
        tokenizer, model = result
    else:
        # ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì²˜ë¦¬
        tokenizer = None
        model = None
        error_msg = result

# ==========================================
# [2] ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ (í¬ë¡¤ë§ & ìš”ì•½)
# ==========================================

def get_naver_blog_content(url):
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì—ì„œ ë³¸ë¬¸ë§Œ ì™ ë½‘ì•„ì˜¤ëŠ” í•¨ìˆ˜"""
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        if "m.blog.naver.com" in url:
            url = url.replace("m.blog.naver.com", "blog.naver.com")

        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        iframe = soup.select_one('iframe#mainFrame')
        if iframe:
            real_url = "https://blog.naver.com" + iframe['src']
            response = requests.get(real_url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')

        title_elem = soup.select_one('.se-title-text') or soup.select_one('.htitle')
        title = title_elem.text.strip() if title_elem else "ì œëª© ì—†ìŒ"

        content_elem = soup.select_one('.se-main-container') or soup.select_one('#postViewArea')
        if content_elem:
            text = content_elem.text
            text = re.sub(r'\n+', ' ', text)
            text = re.sub(r'\s+', ' ', text)
            return title, text.strip()
        return title, None
    except:
        return "ì—ëŸ¬", None

def get_latest_mofa_news():
    """ì™¸êµë¶€ ë¸”ë¡œê·¸ RSSì—ì„œ ìµœì‹ ê¸€ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    rss_url = "https://rss.blog.naver.com/mofakr.xml"
    try:
        response = requests.get(rss_url)
        soup = BeautifulSoup(response.content, 'xml')
        items = soup.find_all('item')
        
        results = []
        for item in items:
            cat = item.category.text if item.category else ""
            if "ì†Œì‹" in cat or "ë³´ë„" in cat or "ëŒ€ë³€ì¸" in cat:
                results.append({"title": item.title.text, "link": item.link.text})
                if len(results) >= 3: break 
        
        if not results:
            results = [{"title": i.title.text, "link": i.link.text} for i in items[:3]]
        return results
    except:
        return []

def summarize(text):
    """ëª¨ë¸ì—ê²Œ ìš”ì•½ì„ ì‹œí‚¤ëŠ” í•¨ìˆ˜"""
    if tokenizer is None: return "ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨"
    
    inputs = tokenizer(text, return_tensors="pt", max_length=1024, truncation=True)
    
    with torch.no_grad():
        summary_ids = model.generate(
            inputs["input_ids"],
            max_length=128,      
            min_length=30,
            length_penalty=1.0,
            num_beams=4,
            early_stopping=True
        )
    
    result = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return result

# ==========================================
# [3] í™”ë©´ ê¾¸ë¯¸ê¸° (UI)
# ==========================================

st.title("ğŸ›ï¸ ì™¸êµë¶€ ì†Œì‹ ìë™ ìš”ì•½ ë´‡")
st.markdown("Assignment 6: **KoBART ëª¨ë¸**ì„ í™œìš©í•œ ë‰´ìŠ¤ ìš”ì•½ ì„œë¹„ìŠ¤")

# ì—ëŸ¬ ë©”ì‹œì§€ ì²˜ë¦¬ (ì¤‘ìš”)
if tokenizer is None:
    st.error("âš ï¸ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    # ì•„ê¹Œ ë°œìƒí•œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í™”ë©´ì— ì°ì–´ì¤ë‹ˆë‹¤.
    if 'error_msg' in locals() and error_msg:
        st.code(f"ì—ëŸ¬ ìƒì„¸: {error_msg}")
    st.warning("ğŸ’¡ íŒ: pip install protobuf sentencepiece ëª…ë ¹ì–´ê°€ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()
else:
    st.success("âœ… AI ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ (ainize/kobart-news)")

# íƒ­ ë§Œë“¤ê¸°
tab1, tab2 = st.tabs(["ğŸ“ í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥", "ğŸ“¡ ì™¸êµë¶€ ì†Œì‹ ìë™ ìˆ˜ì§‘"])

# [Tab 1] ì§ì ‘ ì…ë ¥
with tab1:
    st.header("ê¸°ì‚¬ ë³¸ë¬¸ ìš”ì•½")
    st.caption("ìš”ì•½í•˜ê³  ì‹¶ì€ ê¸´ ê¸€ì„ ì•„ë˜ì— ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
    input_text = st.text_area("ì—¬ê¸°ì— ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”", height=300)
    
    if st.button("ìš”ì•½í•˜ê¸°", key="btn_manual"):
        if len(input_text) > 50:
            with st.spinner("AIê°€ ë‚´ìš©ì„ ì½ê³  ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤..."):
                summary_text = summarize(input_text)
                st.subheader("ğŸ“„ ìš”ì•½ ê²°ê³¼")
                st.info(summary_text)
        else:
            st.warning("ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. 50ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# [Tab 2] ìë™ ìˆ˜ì§‘
with tab2:
    st.header("ì˜¤ëŠ˜ì˜ ì™¸êµë¶€ ë¸Œë¦¬í•‘")
    if st.button("ìµœì‹  ì†Œì‹ ê°€ì ¸ì˜¤ê¸°", type="primary", key="btn_auto"):
        with st.spinner("ì™¸êµë¶€ ë¸”ë¡œê·¸ ìŠ¤ìº” ì¤‘..."):
            news_items = get_latest_mofa_news()
            if news_items:
                st.success(f"ì´ {len(news_items)}ê°œì˜ ìµœì‹  ì†Œì‹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                for idx, item in enumerate(news_items):
                    st.markdown(f"### {idx+1}. [{item['title']}]({item['link']})")
                    title, content = get_naver_blog_content(item['link'])
                    if content:
                        summary_text = summarize(content)
                        st.info(f"**AI ìš”ì•½**: {summary_text}")
                        with st.expander("ì›ë¬¸ ë³´ê¸°"):
                            st.write(content)
                    else:
                        st.error("ë³¸ë¬¸ ì ‘ê·¼ ë¶ˆê°€")
                    st.divider()
            else:
                st.warning("ìƒˆë¡œìš´ ì†Œì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
