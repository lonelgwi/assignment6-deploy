import streamlit as st
import torch
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration
import requests
from bs4 import BeautifulSoup

# --- 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ì™¸êµë¶€ ì†Œì‹ ìš”ì•½ ì„œë¹„ìŠ¤", page_icon="ğŸ“°")

st.title("ğŸ“° AI ë‰´ìŠ¤ ìš”ì•½ ì„œë¹„ìŠ¤")
st.write("Assignment 6: Pre-trained Model(KoBART) í™œìš©")
st.markdown("---")

# --- 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì¸í„°ë„·ì—ì„œ ë‹¤ìš´ë¡œë“œ) ---
# @st.cache_resourceëŠ” ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë‹¤ìš´ë°›ê³  ê³„ì† ì¬ì‚¬ìš©í•˜ê²Œ í•´ì¤ë‹ˆë‹¤.
@st.cache_resource
def load_model():
    # í•œêµ­ì–´ ë‰´ìŠ¤ ìš”ì•½ ì„±ëŠ¥ì´ ì¢‹ì€ 'ainize/kobart-news' ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    model_name = "ainize/kobart-news"
    
    try:
        tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)
        model = BartForConditionalGeneration.from_pretrained(model_name)
        return tokenizer, model
    except Exception as e:
        return None, None

# ë¡œë”© ì• ë‹ˆë©”ì´ì…˜
with st.spinner('ì¸í„°ë„·ì—ì„œ AI ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒë§Œ ì˜¤ë˜ ê±¸ë¦¼)'):
    tokenizer, model = load_model()

if model is None:
    st.error("âš ï¸ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()
else:
    st.success("âœ… AI ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ! (ainize/kobart-news)")

# --- 3. ìš”ì•½ í•¨ìˆ˜ ì •ì˜ ---
def summarize_text(text):
    # ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆê²Œ ë³€í™˜
    input_ids = tokenizer.encode(text, return_tensors="pt")
    
    # ìš”ì•½ë¬¸ ìƒì„± (ë‰´ìŠ¤ ê¸°ì‚¬ì— ì í•©í•œ íŒŒë¼ë¯¸í„° ì„¤ì •)
    summary_text_ids = model.generate(
        input_ids=input_ids,
        bos_token_id=model.config.bos_token_id,
        eos_token_id=model.config.eos_token_id,
        length_penalty=2.0,
        max_length=128,
        min_length=32,
        num_beams=4,
    )
    
    # ìˆ«ìë¡œ ëœ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ê¸€ìë¡œ ë³€í™˜
    return tokenizer.decode(summary_text_ids[0], skip_special_tokens=True)

# --- 4. ìŠ¤í¬ë ˆì´í•‘ í•¨ìˆ˜ (ì°¨ë‹¨ ë°©ì§€ ì ìš©) ---
def scrape_website(url):
    try:
        # ë´‡ì´ ì•„ë‹Œ ì²™ ë¸Œë¼ìš°ì € ì •ë³´(User-Agent) ë³´ë‚´ê¸°
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers)
        
        if response.status_code != 200:
            return f"ì ‘ì† ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})"
            
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë³¸ë¬¸ ì¶”ì¶œ ì‹œë„ (ë‰´ìŠ¤ë‚˜ ë¸”ë¡œê·¸ì˜ ì¼ë°˜ì ì¸ íƒœê·¸ íŒ¨í„´)
        content = ""
        
        # 1ìˆœìœ„: article íƒœê·¸ ì°¾ê¸°
        article = soup.find('article')
        if article:
            content = article.get_text()
        else:
            # 2ìˆœìœ„: idë‚˜ classì— 'content', 'article', 'news'ê°€ ë“¤ì–´ê°€ëŠ” ë¶€ë¶„ ì°¾ê¸°
            paragraphs = soup.find_all('p')
            content = " ".join([p.get_text() for p in paragraphs])
        
        # ê³µë°± ì •ë¦¬
        content = content.replace('\n', ' ').strip()
        
        if len(content) < 50: 
            return "ë‚´ìš©ì„ ì œëŒ€ë¡œ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë³´ì•ˆì´ ê°•í•œ ì‚¬ì´íŠ¸)"
            
        return content
    except Exception as e:
        return f"ì—ëŸ¬ ë°œìƒ: {e}"

# --- 5. í™”ë©´ êµ¬ì„± (íƒ­ ê¸°ëŠ¥) ---
tab1, tab2 = st.tabs(["ğŸŒ URLë¡œ ìš”ì•½í•˜ê¸°", "ğŸ“ ì§ì ‘ ì…ë ¥í•´ì„œ ìš”ì•½í•˜ê¸°"])

# [Tab 1] URL ìŠ¤í¬ë ˆì´í•‘ ë°©ì‹
with tab1:
    st.info("ğŸ’¡ íŒ: ë„¤ì´ë²„ ë‰´ìŠ¤ë‚˜ ì¼ë°˜ ì–¸ë¡ ì‚¬ ê¸°ì‚¬ URLì´ ì˜ ì‘ë™í•©ë‹ˆë‹¤.")
    url_input = st.text_input("ê¸°ì‚¬ URL ì…ë ¥")
    
    if st.button("URL ìš”ì•½ ì‹œì‘", key='btn_url'):
        if url_input:
            with st.spinner('ì‚¬ì´íŠ¸ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...'):
                scraped_text = scrape_website(url_input)
                
            if "ì—ëŸ¬" in scraped_text or "ëª»í–ˆìŠµë‹ˆë‹¤" in scraped_text:
                st.warning("âš ï¸ ìŠ¤í¬ë ˆì´í•‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ í™•ì¸í•˜ê±°ë‚˜ 'ì§ì ‘ ì…ë ¥' íƒ­ì„ ì´ìš©í•˜ì„¸ìš”.")
                st.code(scraped_text)
            else:
                st.success(f"ê¸€ì ìˆ˜: {len(scraped_text)}ì ê°€ì ¸ì˜¤ê¸° ì„±ê³µ!")
                with st.expander("ì›ë¬¸ ë³´ê¸°"):
                    st.write(scraped_text[:1000] + "...") 
                
                # ìš”ì•½ ìˆ˜í–‰
                with st.spinner('AIê°€ ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤...'):
                    result = summarize_text(scraped_text)
                    st.markdown("### ğŸ“„ ìš”ì•½ ê²°ê³¼")
                    st.success(result)
        else:
            st.warning("URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# [Tab 2] í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥ ë°©ì‹ (ì•ˆì „ì¥ì¹˜)
with tab2:
    st.subheader("ê¸°ì‚¬ ë³¸ë¬¸ ì§ì ‘ ë¶™ì—¬ë„£ê¸°")
    st.caption("â€» URL ìš”ì•½ì´ ì•ˆ ë  ê²½ìš°, ê¸°ì‚¬ ë‚´ìš©ì„ ë³µì‚¬í•´ì„œ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
    text_input = st.text_area("í…ìŠ¤íŠ¸ ì…ë ¥", height=300)
    
    if st.button("í…ìŠ¤íŠ¸ ìš”ì•½ ì‹œì‘", key='btn_text'):
        if len(text_input) > 30:
            with st.spinner('AIê°€ ìš”ì•½ ì¤‘...'):
                try:
                    # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ì„œ ì²˜ë¦¬ (ì˜¤ë¥˜ ë°©ì§€)
                    input_text = text_input[:1024] 
                    result = summarize_text(input_text)
                    st.markdown("### ğŸ“„ ìš”ì•½ ê²°ê³¼")
                    st.success(result)
                except Exception as e:
                    st.error(f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        else:
            st.warning("ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")

# --- 6. ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("About Service")
    st.write("ì´ ì„œë¹„ìŠ¤ëŠ” `ainize/kobart-news` ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.markdown("[Streamlit Docs](https://docs.streamlit.io)")
