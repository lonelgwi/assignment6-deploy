import streamlit as st
import torch
import requests
import re
from bs4 import BeautifulSoup
from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast

# ==========================================
# í˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ì™¸êµë¶€ ì†Œì‹ ìš”ì•½ ë´‡", page_icon="ğŸ“¢", layout="wide")

# ==========================================
# [1] ëª¨ë¸ ë¡œë“œ (ì—ëŸ¬ ì›ì²œ ë´‰ì‡„ ë²„ì „)
# ==========================================
@st.cache_resource
def load_model():
    model_name = "ainize/kobart-news"
    try:
        # [ìˆ˜ì •] í† í¬ë‚˜ì´ì € ë¡œë”© ë°©ì‹ ë³€ê²½
        tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)
        model = BartForConditionalGeneration.from_pretrained(model_name)
        return tokenizer, model, None
    except Exception as e:
        return None, None, str(e)

# í™”ë©´ í‘œì‹œ
st.title("ğŸ“¢ ì™¸êµë¶€ ì†Œì‹ ìë™ ìš”ì•½ ë´‡")
st.markdown("Assignment 6: KoBART ë‰´ìŠ¤ ìš”ì•½")

with st.spinner('ëª¨ë¸ ë¡œë”© ì¤‘... (protobuf ë²„ì „ í™•ì¸ í•„ìš”)'):
    tokenizer, model, error_msg = load_model()

if tokenizer is None:
    st.error("âš ï¸ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
    st.error(f"ì—ëŸ¬ ë©”ì‹œì§€: {error_msg}")
    st.warning("ğŸ‘‰ í„°ë¯¸ë„ì— 'pip install protobuf==3.20.3' ì„ ì…ë ¥í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ë³´ì„¸ìš”!")
    st.stop()
else:
    st.success("âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")

# ==========================================
# [2] ê¸°ëŠ¥ í•¨ìˆ˜ë“¤
# ==========================================
def summarize(text):
    if len(text) < 10: return "ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤."
    
    input_ids = tokenizer.encode(text, return_tensors="pt")
    # ê¸¸ì´ ì œí•œ ì•ˆì „ì¥ì¹˜
    if input_ids.shape[1] > 1024: input_ids = input_ids[:, :1024]

    summary_ids = model.generate(
        input_ids,
        max_length=128,
        min_length=30,
        length_penalty=1.0,
        num_beams=4,
        early_stopping=True
    )
    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)

def get_latest_mofa_news():
    # RSS í¬ë¡¤ë§
    try:
        url = "https://rss.blog.naver.com/mofakr.xml"
        res = requests.get(url)
        soup = BeautifulSoup(res.content, "xml")
        items = soup.find_all("item")
        results = []
        for item in items:
            if any(x in (item.category.text if item.category else "") for x in ["ì†Œì‹", "ë³´ë„", "ëŒ€ë³€ì¸"]):
                results.append({"title": item.title.text, "link": item.link.text})
                if len(results) >= 3: break
        return results if results else [{"title": i.title.text, "link": i.link.text} for i in items[:3]]
    except:
        return []

def get_blog_content(url):
    # ë³¸ë¬¸ í¬ë¡¤ë§
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        if "m.blog" in url: url = url.replace("m.blog", "blog")
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        iframe = soup.select_one("iframe#mainFrame")
        if iframe:
            res = requests.get("https://blog.naver.com" + iframe["src"], headers=headers)
            soup = BeautifulSoup(res.text, "html.parser")
        
        body = soup.select_one(".se-main-container") or soup.select_one("#postViewArea")
        return body.text.strip().replace("\n", " ") if body else None
    except:
        return None

# ==========================================
# [3] UI íƒ­
# ==========================================
tab1, tab2 = st.tabs(["ğŸ“ ì§ì ‘ ì…ë ¥", "ğŸ“¡ ìë™ ìˆ˜ì§‘"])

with tab1:
    txt = st.text_area("í…ìŠ¤íŠ¸ ì…ë ¥", height=200)
    if st.button("ìš”ì•½", key="b1") and txt:
        st.info(summarize(txt))

with tab2:
    if st.button("ìµœì‹  ì†Œì‹ ê°€ì ¸ì˜¤ê¸°", key="b2"):
        items = get_latest_mofa_news()
        for i in items:
            st.markdown(f"**{i['title']}** [ë§í¬]({i['link']})")
            content = get_blog_content(i['link'])
            if content:
                st.success(f"ìš”ì•½: {summarize(content)}")
            st.divider()
