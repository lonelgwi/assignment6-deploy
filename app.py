import streamlit as st
import torch
import requests
import re
from bs4 import BeautifulSoup
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ì™¸êµë¶€ ì†Œì‹ ìš”ì•½ ë´‡", page_icon="ğŸ“¢", layout="wide")

# ==========================================
# [1] ëª¨ë¸ ë¡œë“œ (ëª¨ë¸ êµì²´: ainize -> gogamza)
# ==========================================
@st.cache_resource
def load_model():
    # [ì¤‘ìš” ë³€ê²½] ì—ëŸ¬ê°€ ë‚˜ëŠ” 'ainize' ëª¨ë¸ì„ ë²„ë¦¬ê³ , ì›ì¡°ì¸ 'gogamza' ëª¨ë¸ë¡œ êµì²´í•©ë‹ˆë‹¤.
    # ì´ ëª¨ë¸ì€ ìµœì‹  í™˜ê²½ì—ì„œë„ ì—ëŸ¬ ì—†ì´ ì˜ ëŒì•„ê°‘ë‹ˆë‹¤.
    model_name = "gogamza/kobart-summarization"
    
    try:
        tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)
        model = BartForConditionalGeneration.from_pretrained(model_name)
        return tokenizer, model, None
    except Exception as e:
        return None, None, str(e)

st.title("ğŸ“¢ ì™¸êµë¶€ ì†Œì‹ ìë™ ìš”ì•½ ë´‡")
st.markdown("Assignment 6: KoBART ë‰´ìŠ¤ ìš”ì•½ ì„œë¹„ìŠ¤")

# ë¡œë”© í‘œì‹œ
with st.spinner('ì •ìƒì ì¸ AI ëª¨ë¸(gogamza)ì„ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...'):
    tokenizer, model, error_msg = load_model()

if tokenizer is None:
    st.error("âš ï¸ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
    st.error(f"ì—ëŸ¬ ë‚´ìš©: {error_msg}")
    st.stop()
else:
    st.success("âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")

# ==========================================
# [2] ê¸°ëŠ¥ í•¨ìˆ˜ë“¤
# ==========================================

def summarize(text):
    """ìš”ì•½ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(text) < 10: return "ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤."
    
    # í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì´í•´í•˜ëŠ” ìˆ«ìë¡œ ë³€í™˜
    input_ids = tokenizer.encode(text, return_tensors="pt")
    
    # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (1024 í† í° ì œí•œ)
    if input_ids.shape[1] > 1024:
        input_ids = input_ids[:, :1024]

    # ìš”ì•½ ìƒì„±
    summary_ids = model.generate(
        input_ids,
        num_beams=4,
        max_length=128,
        min_length=30,
        no_repeat_ngram_size=3,
        early_stopping=True,
        eos_token_id=375 # ë¬¸ì¥ ë ì•Œë¦¼
    )
    
    result = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return result

def get_latest_mofa_news():
    """RSS í¬ë¡¤ë§"""
    try:
        url = "https://rss.blog.naver.com/mofakr.xml"
        res = requests.get(url, timeout=5)
        soup = BeautifulSoup(res.content, "xml")
        items = soup.find_all("item")
        
        results = []
        for item in items:
            cat = item.category.text if item.category else ""
            if any(x in cat for x in ["ì†Œì‹", "ë³´ë„", "ëŒ€ë³€ì¸"]):
                results.append({"title": item.title.text, "link": item.link.text})
                if len(results) >= 3: break
        
        if not results: # ì—†ìœ¼ë©´ ìµœì‹ ê¸€ 3ê°œ
            return [{"title": i.title.text, "link": i.link.text} for i in items[:3]]
            
        return results
    except:
        return []

def get_blog_content(url):
    """ë³¸ë¬¸ í¬ë¡¤ë§"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        if "m.blog" in url: url = url.replace("m.blog", "blog")
        
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        
        iframe = soup.select_one("iframe#mainFrame")
        if iframe:
            res = requests.get("https://blog.naver.com" + iframe["src"], headers=headers)
            soup = BeautifulSoup(res.text, "html.parser")
            
        body = soup.select_one(".se-main-container") or soup.select_one("#postViewArea")
        
        if body:
            return body.text.strip().replace("\n", " ")
        return None
    except:
        return None

# ==========================================
# [3] UI í™”ë©´
# ==========================================
tab1, tab2 = st.tabs(["ğŸ“ ì§ì ‘ ì…ë ¥", "ğŸ“¡ ìë™ ìˆ˜ì§‘"])

# íƒ­ 1: ì§ì ‘ ì…ë ¥
with tab1:
    st.subheader("ë‰´ìŠ¤ ê¸°ì‚¬ ì…ë ¥")
    txt = st.text_area("ìš”ì•½í•  ê¸€ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”", height=200)
    if st.button("ìš”ì•½í•˜ê¸°", key="b1"):
        if txt:
            with st.spinner("ìš”ì•½ ì¤‘..."):
                st.info(summarize(txt))
        else:
            st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")

# íƒ­ 2: ìë™ ìˆ˜ì§‘
with tab2:
    st.subheader("ì™¸êµë¶€ ì†Œì‹ ìë™ ìˆ˜ì§‘")
    if st.button("ìµœì‹  ì†Œì‹ ê°€ì ¸ì˜¤ê¸°", key="b2"):
        with st.spinner("ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            items = get_latest_mofa_news()
            if not items:
                st.error("ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for i in items:
                    st.markdown(f"**{i['title']}**")
                    st.caption(f"[ì›ë¬¸ ë§í¬]({i['link']})")
                    
                    content = get_blog_content(i['link'])
                    if content:
                        result = summarize(content)
                        st.success(f"ìš”ì•½: {result}")
                        with st.expander("ì›ë¬¸ ë³´ê¸°"):
                            st.write(content)
                    else:
                        st.error("ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    st.divider()
