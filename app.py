import streamlit as st
import torch
import requests
import re
from bs4 import BeautifulSoup
# [ìˆ˜ì •] í˜¸í™˜ì„±ì„ ìœ„í•´ AutoTokenizer ì‚¬ìš©
from transformers import AutoTokenizer, BartForConditionalGeneration

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ì™¸êµë¶€ ì†Œì‹ ìš”ì•½ ì„œë¹„ìŠ¤", page_icon="ğŸ“¢", layout="wide")

st.title("ğŸ“¢ ì™¸êµë¶€ ì†Œì‹ ìë™ 3ì¤„ ìš”ì•½ê¸°")
st.markdown("Assignment 6: ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ë¡¤ë§ ë° KoBART ìš”ì•½ ì„œë¹„ìŠ¤")
st.markdown("---")

# --- 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì—ëŸ¬ í•´ê²°: use_fast=False ì ìš©) ---
@st.cache_resource
def load_model():
    model_name = "ainize/kobart-news"
    try:
        # [í•µì‹¬ ìˆ˜ì •] use_fast=False ì˜µì…˜ì„ ë„£ì–´ì„œ í˜¸í™˜ì„± ì—ëŸ¬(add_prefix_space...)ë¥¼ í”¼í•©ë‹ˆë‹¤.
        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
        model = BartForConditionalGeneration.from_pretrained(model_name)
        return tokenizer, model, None 
    except Exception as e:
        return None, None, str(e)

with st.spinner('AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)'):
    tokenizer, model, error_msg = load_model()

# ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì´ìœ  ì¶œë ¥
if model is None:
    st.error("âš ï¸ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
    st.error(f"ì—ëŸ¬ ìƒì„¸: {error_msg}")
    st.stop()

# --- 3. í¬ë¡¤ë§ í•¨ìˆ˜ (RSS & Iframe ëŒ€ì‘) ---
def get_naver_blog_content(url):
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ì˜ Iframeì„ ëš«ê³  ì‹¤ì œ ë³¸ë¬¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        # ëª¨ë°”ì¼ ë§í¬ ë³µêµ¬
        if "m.blog.naver.com" in url:
            url = url.replace("m.blog.naver.com", "blog.naver.com")

        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        # Iframe src ì°¾ê¸°
        iframe = soup.select_one('iframe#mainFrame')
        if iframe:
            real_url = "https://blog.naver.com" + iframe['src']
            response = requests.get(real_url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')

        # ì œëª© ì¶”ì¶œ
        title_elem = soup.select_one('.se-title-text') or soup.select_one('.htitle')
        title = title_elem.text.strip() if title_elem else "ì œëª© ì—†ìŒ"

        # ë³¸ë¬¸ ì¶”ì¶œ
        content_elem = soup.select_one('.se-main-container') or soup.select_one('#postViewArea')

        if content_elem:
            text = content_elem.text
            text = re.sub(r'\n+', ' ', text) # ì¤„ë°”ê¿ˆ ì •ë¦¬
            text = re.sub(r'\s+', ' ', text) # ê³µë°± ì •ë¦¬
            return title, text.strip()
        else:
            return title, None
    except Exception as e:
        return "ì—ëŸ¬ ë°œìƒ", None

def get_latest_mofa_news():
    """ì™¸êµë¶€ ë¸”ë¡œê·¸ RSSì—ì„œ ìµœì‹  ë‰´ìŠ¤ ë§í¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    rss_url = "https://rss.blog.naver.com/mofakr.xml"
    
    try:
        response = requests.get(rss_url)
        soup = BeautifulSoup(response.content, 'xml')
        items = soup.find_all('item')

        target_links = []
        for item in items:
            category = item.category.text if item.category else ""
            title = item.title.text
            link = item.link.text

            # í‚¤ì›Œë“œ í•„í„°ë§
            if any(keyword in category for keyword in ["ì†Œì‹", "ë³´ë„", "ëŒ€ë³€ì¸"]):
                target_links.append({"title": title, "link": link})
                if len(target_links) >= 3: break # 3ê°œë§Œ ìˆ˜ì§‘
        
        # í•„í„°ë§ ëœ ê²Œ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ìµœì‹ ê¸€ 3ê°œ
        if not target_links:
             target_links = [{"title": i.title.text, "link": i.link.text} for i in items[:3]]

        return target_links
    except Exception as e:
        return []

# --- 4. ìš”ì•½ ë° í›„ì²˜ë¦¬ í•¨ìˆ˜ ---
def predict_summary(text):
    # ì…ë ¥ ê¸¸ì´ ìë¥´ê¸°
    input_ids = tokenizer.encode(text, return_tensors="pt")
    if input_ids.shape[1] > 1024:
        input_ids = input_ids[:, :1024]

    # ëª¨ë¸ ìƒì„±
    summary_ids = model.generate(
        input_ids,
        max_length=120,       
        min_length=50,
        length_penalty=1.5,
        num_beams=4,
        early_stopping=True,
        no_repeat_ngram_size=3
    )
    
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

    # [3ì¤„ í¬ë§·íŒ… í›„ì²˜ë¦¬]
    sentences = re.split(r'(?<!\d\.)(?<=[.!?])\s*', summary)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    formatted = sentences[:3] 
    return formatted

# --- 5. UI êµ¬ì„± ---
tab1, tab2 = st.tabs(["ğŸ›ï¸ ì™¸êµë¶€ ì†Œì‹ ìë™ ìˆ˜ì§‘", "ğŸ“ ì§ì ‘ ì…ë ¥ ìš”ì•½"])

# [Tab 1] ìë™ ìˆ˜ì§‘
with tab1:
    st.header("ë„¤ì´ë²„ ë¸”ë¡œê·¸ RSS ê¸°ë°˜ ìë™ í¬ë¡¤ë§")
    st.info("ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ 'ì™¸êµë¶€ ì„œí¬í„°ì¦ˆ' ë¸”ë¡œê·¸ì˜ ìµœì‹  ê¸€ì„ ê°€ì ¸ì™€ ìš”ì•½í•©ë‹ˆë‹¤.")

    if st.button("ğŸš€ ìµœì‹  ì†Œì‹ ê°€ì ¸ì˜¤ê¸°", key="btn_auto"):
        with st.spinner("RSS ê²€ìƒ‰ ì¤‘..."):
            news_items = get_latest_mofa_news()
        
        if not news_items:
            st.error("RSS ì—°ê²° ì‹¤íŒ¨. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            st.success(f"ì´ {len(news_items)}ê°œì˜ ìµœì‹  ê¸€ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
            
            for i, item in enumerate(news_items):
                st.markdown(f"### {i+1}. {item['title']}")
                st.caption(f"[ì›ë¬¸ ë³´ëŸ¬ê°€ê¸°]({item['link']})")
                
                with st.spinner("ë³¸ë¬¸ ì½ê³  ìš”ì•½ ì¤‘..."):
                    title, content = get_naver_blog_content(item['link'])
                    
                    if content and len(content) > 50:
                        summary_list = predict_summary(content)
                        st.markdown("**[AI 3ì¤„ ìš”ì•½]**")
                        for s in summary_list:
                            st.write(f"- {s}")
                    else:
                        st.warning("âš ï¸ ë³¸ë¬¸ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë³´ì•ˆ ì„¤ì • ë“±)")
                st.markdown("---")

# [Tab 2] ì§ì ‘ ì…ë ¥
with tab2:
    st.subheader("ë‰´ìŠ¤ ë³¸ë¬¸ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”")
    input_text = st.text_area("í…ìŠ¤íŠ¸ ì…ë ¥", height=200)
    
    if st.button("ìš”ì•½í•˜ê¸°", key="btn_manual"):
        if len(input_text) > 30:
            with st.spinner("ìš”ì•½ ì¤‘..."):
                summary_list = predict_summary(input_text)
                st.success("âœ… ìš”ì•½ ì™„ë£Œ")
                for s in summary_list:
                    st.write(f"- {s}")
        else:
            st.warning("ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
